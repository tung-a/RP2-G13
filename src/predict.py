import joblib
import pandas as pd
import os
import itertools
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import argparse 
import shap # Import do SHAP adicionado ao topo

def predict_permanence(student_data, model_name, institution_type):
    """
    Carrega um modelo espec√≠fico e o pr√©-processador para prever o tempo de perman√™ncia.
    """
    MODELS_PATH = 'models'
    # Alvo: Carregar o melhor modelo salvo pelo runtests.py
    model_path = os.path.join(MODELS_PATH, f'{model_name}_{institution_type}_best.joblib')
    preprocessor_path = os.path.join(MODELS_PATH, f'preprocessor_{institution_type}.joblib')

    # Fallback: Se o modelo do runtests n√£o existir, tenta carregar o do main.py
    if not os.path.exists(model_path):
        fallback_path = os.path.join(MODELS_PATH, f'permanencia_model_{institution_type}.joblib')
        if os.path.exists(fallback_path):
            model_path = fallback_path
        else:
            return f"Modelo '{model_name}' para institui√ß√£o '{institution_type}' n√£o encontrado. Execute o runtests.py ou main.py primeiro."

    if not os.path.exists(preprocessor_path):
        return f"Pr√©-processador para '{institution_type}' n√£o encontrado."

    model = joblib.load(model_path)
    preprocessor = joblib.load(preprocessor_path)

    student_df = pd.DataFrame([student_data])
    processed_data = preprocessor.transform(student_df)
    prediction = model.predict(processed_data)

    return prediction[0]

def run_and_save_all_scenarios(model_name):
    """
    (AN√ÅLISE EXAUSTIVA)
    Gera, testa, compara com o tempo ideal e guarda num CSV todas as combina√ß√µes
    poss√≠veis de perfis de alunos para um modelo espec√≠fico.
    """
    print(f"--- INICIANDO TESTE EXAUSTIVO DE TODOS OS CEN√ÅRIOS PARA O MODELO: {model_name} ---")

    possible_values = {
        'tp_cor_raca': {0: "N√£o declarado", 1: "Branca", 2: "Preta", 3: "Parda", 4: "Amarela", 5: "Ind√≠gena"},
        'tp_sexo': {1: "Masculino", 2: "Feminino"},
        'tp_escola_conclusao_ens_medio': {1: "Privada", 2: "P√∫blica"},
        'tp_modalidade_ensino': {1: "Presencial", 2: "EAD"},
        'in_financiamento_estudantil': {0: "N√£o", 1: "Sim"},
        'in_apoio_social': {0: "N√£o", 1: "Sim"}
    }
    
    igc_faixas = {1: 0.5, 2: 1.5, 3: 2.5, 4: 3.5, 5: 4.5}
    base_values_template = {
        'faixa_etaria': 3,
        'tp_grau_academico': 1,
        'nu_carga_horaria': 3600,
        'duracao_ideal_anos': 4.0, # Assumindo 4 anos para um curso de 3600 horas
    }

    keys = possible_values.keys()
    value_codes = [list(v.keys()) for v in possible_values.values()]
    all_combinations = list(itertools.product(*value_codes))
    
    total_scenarios = len(all_combinations) * 2 * len(igc_faixas)
    print(f"Total de cen√°rios a serem calculados: {total_scenarios}")
    results = []
    
    count = 0

    for combo in all_combinations:
        for igc_faixa, igc_value in igc_faixas.items():
            student_profile = base_values_template.copy()
            student_profile['igc'] = igc_value
            
            for i, key in enumerate(keys):
                student_profile[key] = combo[i]

            for inst_type, inst_code in [('publica', 1), ('privada', 5)]:
                count += 1
                if count % 1000 == 0 or count == total_scenarios:
                    print(f"  -> Calculando cen√°rio {count} de {total_scenarios}...", end='\r')

                profile_for_prediction = student_profile.copy()
                profile_for_prediction['tp_categoria_administrativa'] = inst_code
                
                prediction = predict_permanence(profile_for_prediction, model_name, inst_type)

                if isinstance(prediction, float):
                    diferenca = prediction - profile_for_prediction['duracao_ideal_anos']
                    if diferenca < -0.5: status = 'Evas√£o Prov√°vel'
                    elif diferenca > 0.5: status = 'Atraso'
                    else: status = 'Conclus√£o no Prazo'
                    
                    profile_description = {
                        "Cor/Ra√ßa": possible_values['tp_cor_raca'][profile_for_prediction['tp_cor_raca']],
                        "Sexo": possible_values['tp_sexo'][profile_for_prediction['tp_sexo']],
                        "Escola M√©dia": possible_values['tp_escola_conclusao_ens_medio'][profile_for_prediction['tp_escola_conclusao_ens_medio']],
                        "Modalidade": possible_values['tp_modalidade_ensino'][profile_for_prediction['tp_modalidade_ensino']],
                        "Financiamento": possible_values['in_financiamento_estudantil'][profile_for_prediction['in_financiamento_estudantil']],
                        "Apoio Social": possible_values['in_apoio_social'][profile_for_prediction['in_apoio_social']],
                        "Faixa IGC": igc_faixa
                    }
                    
                    results.append({
                        "Tipo IES": inst_type.upper(),
                        **profile_description,
                        "Previs√£o (anos)": round(prediction, 2),
                        "Dura√ß√£o Ideal (anos)": profile_for_prediction['duracao_ideal_anos'],
                        "Status Conclus√£o": status
                    })

    results_df = pd.DataFrame(results)
    
    REPORTS_PATH = 'reports'
    os.makedirs(REPORTS_PATH, exist_ok=True)
    output_path = os.path.join(REPORTS_PATH, f'prediction_scenarios_{model_name}.csv')
    results_df.to_csv(output_path, index=False)
    
    print(f"\n--- Todos os {len(results_df)} cen√°rios foram guardados em: {output_path} ---")
    return output_path

def analyze_predictions(csv_path):
    """
    (AN√ÅLISE EXAUSTIVA - GR√ÅFICOS)
    L√™ o ficheiro CSV com as previs√µes, realiza an√°lises e GERA GR√ÅFICOS para extrair insights.
    """
    if not os.path.exists(csv_path):
        print(f"Ficheiro de cen√°rios n√£o encontrado em {csv_path}")
        return

    print(f"\n\n--- INICIANDO AN√ÅLISE DOS CEN√ÅRIOS GERADOS EM: {csv_path} ---")
    df = pd.read_csv(csv_path)
    
    FIGURES_PATH = 'reports/figures'
    os.makedirs(FIGURES_PATH, exist_ok=True)
    model_name = os.path.basename(csv_path).replace('prediction_scenarios_', '').replace('.csv', '')

    # An√°lise 1: Distribui√ß√£o do Status de Conclus√£o
    print("\n[An√°lise 1: Distribui√ß√£o do Status de Conclus√£o Previsto]")
    plt.figure(figsize=(12, 7))
    sns.countplot(x='Status Conclus√£o', hue='Tipo IES', data=df, order=['Evas√£o Prov√°vel', 'Conclus√£o no Prazo', 'Atraso'], palette='mako')
    plt.title(f'Distribui√ß√£o Prevista do Status de Conclus√£o ({model_name})', fontsize=16, fontweight='bold')
    plt.ylabel('N√∫mero de Cen√°rios de Alunos', fontsize=12)
    plt.xlabel('Status de Conclus√£o Previsto', fontsize=12)
    status_plot_path = os.path.join(FIGURES_PATH, f'impacto_status_conclusao_{model_name}.png')
    plt.savefig(status_plot_path)
    plt.close()
    print(f"-> Gr√°fico de status de conclus√£o guardado em: {status_plot_path}")

    # An√°lise 2: Impacto M√©dio de Cada Caracter√≠stica
    print("\n[An√°lise 2: Impacto M√©dio de Cada Caracter√≠stica na Previs√£o]")
    features_to_analyze = ["Modalidade", "Escola M√©dia", "Financiamento", "Apoio Social", "Cor/Ra√ßa", "Faixa IGC"]
    
    for feature in features_to_analyze:
        combined_impact = df.groupby(['Tipo IES', feature])['Previs√£o (anos)'].mean().reset_index()
        plt.style.use('seaborn-v0_8-whitegrid')
        plt.figure(figsize=(12, 8))
        ax = sns.barplot(x=feature, y='Previs√£o (anos)', hue='Tipo IES', data=combined_impact, palette={'PUBLICA': '#2c7fb8', 'PRIVADA': '#41b6c4'})
        plt.title(f'Impacto M√©dio da Caracter√≠stica "{feature}" ({model_name})', fontsize=16, fontweight='bold')
        plt.ylabel('Previs√£o M√©dia de Perman√™ncia (anos)', fontsize=12)
        plt.xlabel(feature, fontsize=12)
        plt.xticks(rotation=45, ha='right')
        for container in ax.containers:
            for p in container.patches:
                height = p.get_height()
                ax.text(p.get_x() + p.get_width() / 2., height, f'{height:.2f}', ha='center', va='bottom', fontsize=10)
        plt.tight_layout()
        plot_path = os.path.join(FIGURES_PATH, f'impacto_combinado_{feature.lower().replace("/", "")}_{model_name}.png')
        plt.savefig(plot_path)
        plt.close()
        print(f"-> Gr√°fico combinado para '{feature}' guardado em: {plot_path}")

    # An√°lise 3: Cen√°rios Extremos
    print("\n\n[An√°lise 3: Perfis com Maiores e Menores Previs√µes]")
    for inst_type in ['PUBLICA', 'PRIVADA']:
        subset_df = df[df['Tipo IES'] == inst_type].copy()
        if not subset_df.empty:
            max_pred = subset_df.loc[subset_df['Previs√£o (anos)'].idxmax()]
            min_pred = subset_df.loc[subset_df['Previs√£o (anos)'].idxmin()]
            
            print(f"\nCen√°rio com MAIOR tempo de perman√™ncia previsto para IES {inst_type} (Modelo: {model_name}):")
            print(max_pred.to_string())
            
            print(f"\nCen√°rio com MENOR tempo de perman√™ncia previsto para IES {inst_type} (Modelo: {model_name}):")
            print(min_pred.to_string())

def analyze_model_with_shap(model_name):
    """
    (AN√ÅLISE SHAP)
    Carrega o modelo e o pr√©-processador e roda a an√°lise SHAP
    para entender o impacto *real* de TODAS as features.
    """
    print(f"\n\n--- INICIANDO AN√ÅLISE DE INTERPRETABILIDADE (SHAP) PARA: {model_name} ---")
    
    MODELS_PATH = 'models'
    REPORTS_PATH = 'reports'
    FIGURES_PATH = os.path.join(REPORTS_PATH, 'figures', 'shap')
    os.makedirs(FIGURES_PATH, exist_ok=True)
    
    for inst_type in ['publica', 'privada']:
        print(f"\nAnalisando modelo para IES: {inst_type.upper()}")
        
        # --- 1. Carregar Modelo e Preprocessor ---
        model_path = os.path.join(MODELS_PATH, f'{model_name}_{inst_type}_best.joblib')
        preprocessor_path = os.path.join(MODELS_PATH, f'preprocessor_{inst_type}.joblib')

        if not os.path.exists(model_path):
            model_path = os.path.join(MODELS_PATH, f'permanencia_model_{inst_type}.joblib')

        if not os.path.exists(model_path) or not os.path.exists(preprocessor_path):
            print(f"Modelo ou pr√©-processador para '{inst_type}' n√£o encontrado. Pulando an√°lise SHAP.")
            continue

        model = joblib.load(model_path)
        preprocessor = joblib.load(preprocessor_path)

        # --- 2. Carregar Dados de Fundo (ESSENCIAL) ---
        try:
            X_test = pd.read_csv(f'data/{inst_type}_sample.csv') 
        except FileNotFoundError:
            print(f"ERRO: Dados de teste (ex: 'data/{inst_type}_sample.csv') n√£o encontrados.")
            print("A an√°lise SHAP precisa de dados de exemplo para funcionar. Pulando...")
            continue
        except Exception as e:
            print(f"ERRO ao carregar 'data/{inst_type}_sample.csv': {e}. Pulando...")
            continue

        # --- 3. Pr√©-processar os Dados de Fundo ---
        X_test_cleaned = X_test.copy()
        
        TARGET_DTYPES = {
            'tp_cor_raca': 'object', 'tp_sexo': 'object', 'faixa_etaria': 'float64',
            'in_financiamento_estudantil': 'float64', 'in_apoio_social': 'float64',
            'tp_escola_conclusao_ens_medio': 'object', 'sigla_uf_curso': 'object',
            'tp_grau_academico': 'object', 'tp_modalidade_ensino': 'object',
            'nu_carga_horaria': 'int64', 'nm_categoria': 'object', 'pib': 'int64',
            'inscritos_por_vaga': 'float64', 'duracao_ideal_anos': 'float64',
            'tp_categoria_administrativa': 'object', 'no_regiao_ies': 'object',
            'igc': 'float64', 'taxa_integralizacao': 'float64'
        }
        
        X_test_cleaned = X_test_cleaned.loc[:, X_test_cleaned.columns.isin(TARGET_DTYPES.keys())]
        print("\nTratando NaN e coer√ß√£o de tipos...")
        
        if 'tp_sexo' in X_test_cleaned.columns:
            X_test_cleaned['tp_sexo'] = X_test_cleaned['tp_sexo'].astype(object)
            X_test_cleaned.loc[X_test_cleaned['tp_sexo'] == 1, 'tp_sexo'] = True
            X_test_cleaned.loc[X_test_cleaned['tp_sexo'] == 2, 'tp_sexo'] = False
            X_test_cleaned['tp_sexo'] = X_test_cleaned['tp_sexo'].astype(bool)

        for col, dtype in TARGET_DTYPES.items():
            if col not in X_test_cleaned.columns or col == 'tp_sexo':
                continue 

            if dtype in ['float64', 'int64']:
                if dtype == 'int64':
                    X_test_cleaned[col] = pd.to_numeric(X_test_cleaned[col], errors='coerce').fillna(0).astype('int64')
                elif dtype == 'float64':
                    X_test_cleaned[col] = pd.to_numeric(X_test_cleaned[col], errors='coerce').fillna(0.0).astype('float64')
            elif dtype == 'object':
                X_test_cleaned[col] = X_test_cleaned[col].astype(str).fillna('0').astype('object')
        
        print("Tipos de dados finais (prontos para o preprocessor):")
        print(X_test_cleaned.info())
        
        print("\nIniciando preprocessor.transform()...")
        X_test_processed = preprocessor.transform(X_test_cleaned)
        print("preprocessor.transform() conclu√≠do.")
        
        if hasattr(X_test_processed, "toarray"):
             X_test_processed_dense = X_test_processed.toarray()
             print(f"Convers√£o de matriz esparsa para densa conclu√≠da. Shape: {X_test_processed_dense.shape}")
        else:
             X_test_processed_dense = X_test_processed

        try:
            feature_names = preprocessor.get_feature_names_out()
        except AttributeError:
            try:
                feature_names = preprocessor.named_steps['preprocessor'].get_feature_names_out()
            except Exception:
                print("Aviso: N√£o foi poss√≠vel obter nomes de features do preprocessor. Usando nomes originais.")
                feature_names = X_test_cleaned.columns.tolist() 
                
        if len(feature_names) != X_test_processed_dense.shape[1]:
             print(f"Alerta: Discrep√¢ncia de colunas! Nomes: {len(feature_names)}, Processadas: {X_test_processed_dense.shape[1]}")
             if len(X_test_cleaned.columns) == X_test_processed_dense.shape[1]:
                  feature_names = X_test_cleaned.columns.tolist()
             else:
                  feature_names = [f'feature_{i}' for i in range(X_test_processed_dense.shape[1])]

        X_test_processed_df = pd.DataFrame(X_test_processed_dense, columns=feature_names)

        # --- 4. Calcular e Plotar SHAP ---
        if model_name in ['RandomForest', 'LightGBM', 'GradientBoosting']:
            explainer = shap.TreeExplainer(model)
            print("Usando TreeExplainer (R√°pido)...")
        else:
            print("Usando KernelExplainer (pode ser lento)...")
            def predict_fn(x):
                if isinstance(x, pd.DataFrame):
                    x = x.values
                if hasattr(x, "toarray"):
                    x = x.toarray()
                return model.predict(x)

            X_test_sample = shap.sample(X_test_processed_df, 100 if X_test_processed_df.shape[0] > 100 else X_test_processed_df.shape[0]) 
            explainer = shap.KernelExplainer(predict_fn, X_test_sample)

        print("Calculando valores SHAP...")
        shap_values = explainer.shap_values(X_test_processed_df) 
        print("Valores SHAP calculados.")

        # --- Gr√°fico 1: Summary Plot (Import√¢ncia Global) ---
        plt.figure(figsize=(16, 10))
        shap.summary_plot(shap_values, X_test_processed_df, plot_type="bar", show=False)
        plt.title(f'Import√¢ncia Global das Features (SHAP) - {inst_type.upper()} ({model_name})')
        plt.tight_layout()
        plot_path = os.path.join(FIGURES_PATH, f'shap_summary_bar_{inst_type}_{model_name}.png')
        plt.savefig(plot_path, bbox_inches='tight')
        plt.close()
        print(f"-> Gr√°fico de import√¢ncia SHAP (bar) salvo em: {plot_path}")

        # --- Gr√°fico 2: Beeswarm Plot (Impacto e Dire√ß√£o) ---
        plt.figure(figsize=(16, 10))
        shap.summary_plot(shap_values, X_test_processed_df, show=False)
        plt.title(f'Impacto Detalhado das Features (SHAP) - {inst_type.upper()} ({model_name})')
        plt.tight_layout()
        plot_path = os.path.join(FIGURES_PATH, f'shap_summary_beeswarm_{inst_type}_{model_name}.png')
        plt.savefig(plot_path, bbox_inches='tight')
        plt.close()
        print(f"-> Gr√°fico de impacto SHAP (beeswarm) salvo em: {plot_path}")

# =============================================================================
# BLOCO DE EXECU√á√ÉO PRINCIPAL (MAIN)
# =============================================================================
if __name__ == '__main__':
    
    # --- Configura√ß√£o dos Argumentos ---
    parser = argparse.ArgumentParser(
        description='Executa an√°lises de interpretabilidade (SHAP) ou simula√ß√£o exaustiva de cen√°rios para modelos de previs√£o de perman√™ncia.'
    )
    
    # Argumento 1: Escolha do Modelo
    parser.add_argument(
        '--model', 
        type=str, 
        default='RandomForest',
        choices=['RandomForest', 'LightGBM', 'GradientBoosting', 'SVR', 'Ridge'],
        help='Escolha o modelo base para executar a an√°lise.'
    )
    
    # Argumento 2: Escolha do Tipo de An√°lise (NOVO AJUSTE)
    parser.add_argument(
        '--analysis', 
        type=str, 
        default='shap', # Pode mudar o default se preferir
        choices=['exhaustive', 'shap'],
        help='Escolha o tipo de an√°lise: "exhaustive" (simula todos os cen√°rios e gera gr√°ficos) ou "shap" (an√°lise de interpretabilidade).'
    )
    
    args = parser.parse_args()

    # --- Execu√ß√£o com base nos argumentos ---
    
    print(f"==================================================")
    print(f"Modelo selecionado: {args.model}")
    print(f"Tipo de an√°lise selecionada: {args.analysis}")
    print(f"==================================================")

    if args.analysis == 'shap':
        analyze_model_with_shap(args.model)
    
    elif args.analysis == 'exhaustive':
        # Roda a simula√ß√£o exaustiva e DEPOIS a an√°lise dos resultados
        print("\nIniciando simula√ß√£o de cen√°rios (exaustiva)...")
        scenarios_csv_path = run_and_save_all_scenarios(args.model)
        
        if scenarios_csv_path and os.path.exists(scenarios_csv_path):
            # Se o CSV foi criado, analisa os resultados
            analyze_predictions(scenarios_csv_path)
        else:
            print("A an√°lise exaustiva n√£o produziu um ficheiro CSV. A an√°lise dos resultados foi pulada.")
    
    print("\n--- FIM DA EXECU√á√ÉO ---")


# an√°lise SHAP (SHapley Additive exPlanations) √© uma t√©cnica de interpretabilidade de modelos de Machine Learning que busca explicar a contribui√ß√£o de cada vari√°vel (feature) para uma previs√£o espec√≠fica.

# Em uma an√°lise SHAP, as vari√°veis "Feature Value" e "SHAP Value" indicam o seguinte:

# üí° Feature Value (Valor da Vari√°vel)
# O Feature Value √© o valor real que uma vari√°vel espec√≠fica assumiu para a inst√¢ncia (linha de dados, amostra) que est√° sendo analisada.

# Em outras palavras, √© o dado de entrada daquela feature para fazer a previs√£o.

# Em gr√°ficos SHAP, a cor do ponto costuma representar o Feature Value (por exemplo, vermelho para valores altos da feature e azul para valores baixos).

# üéØ SHAP Value (Valor SHAP)
# O SHAP Value representa a contribui√ß√£o dessa feature (com seu Feature Value espec√≠fico) para a diferen√ßa entre a previs√£o do modelo para aquela inst√¢ncia e a previs√£o m√©dia (ou valor base) de todas as inst√¢ncias.

# Positivo SHAP Value: Indica que o valor da vari√°vel contribuiu para aumentar a previs√£o do modelo em rela√ß√£o ao valor base.

# Negativo SHAP Value: Indica que o valor da vari√°vel contribuiu para diminuir a previs√£o do modelo em rela√ß√£o ao valor base.

# O m√≥dulo (valor absoluto) do SHAP Value indica a magnitude da influ√™ncia. Vari√°veis com altos valores absolutos s√£o consideradas mais importantes para a previs√£o daquela inst√¢ncia.